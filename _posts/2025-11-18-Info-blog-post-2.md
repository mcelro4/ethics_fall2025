---
title: 'Info Blog 2: ARTificial: Why Copyright Is Not the Right Policy Tool to Deal with Generative AI'
date: 2025-11-18
permalink: /posts/2025/11/Info Copyright-blog-post-2/
tags:
  - Copyright
  - GAI
  - ARTificial
---
**Article:**  
[ARTificial: Why Copyright Is Not the Right Policy Tool to Deal with Generative AI](https://yalelawjournal.org/forum/artificial-why-copyright-is-not-the-right-policy-tool-to-deal-with-generative-ai)

Brief Summary

Rapid Advancement of GAI raise complex and ethical issues reagrding originality. This article dives into the philsophical, legal, and practical dimensions of copyright challenges and who or what should be compnesated for their work.

Discussion Questions:

How should authors be compensated, and under which circumstances?

Authors should be compensated for the work done by themselves that AI uses to train on large datasets. GAI should be required to compensate others for their work before using it, which would serve as a form of compensation to creators. In this scenario, some form of compensation should be present. The article argues that copyright is no longer sufficient today. Working towards consent from authors as well as recognition is a way that authors can be credited for their work, in hopes to bring more traffic towards the artist and away from work that GAI systems output without recognition of the primary source.

Is training with unlicensed works a fair use, or an infringing one?

I think it depends on the situation. I believe that training with unlicensed work heavily determines if it's fair or not. In a real-world example, let's say a news source finds that OpenAI has been training on their work. It would be unfair if OpenAI tailors their output exactly to how the news source shares its information, because then OpenAI would be in competition, as people tend to have shorter attention spans. AI can give a quick analysis of topics that take less time to read. A fair use would be AI using the information to break down content and create new knowledge that GAI systems can build off of, rather than taking information directly and outputting it to users. 

Are the outputs generated by GAI original or derivative works?

I think that if the output of GAI is relatively close to the creator's work, in which it recreates or closely resembles original work, it is derivative. In our most recent podcast about black mirror episodes, my partner and I talked about artists having their voices scanned and copied so that LLMs can use them to create songs that sound similar to the real artist. This would be a case of derivative work. However, the article mentions how "latent representations are not 'copies' as defined by copyright law, and the outputs of a GAI model are not necessarily a derivative work in the sense of there being a direct correlation between the 'original”. This leaves the discussion open-ended as it solely depends on the situation. An example would be a student putting an article into ChatGPT and prompting the LLM to create a baseline of how they want to structure their work, using the article given. This is a latent representation as it creates a simplified version of how the student can structure their work, including essential features, without copying work from the original article. Overall, whether a GAI output is derivative or original depends on how closely it replicates copyrighted work and whether it reproduces protected material rather than general ideas or patterns.

Should we distinguish between autonomous and assisted AI creations? Can AI be assigned rights as an author for its contributions in some capacity? If so, where should the line be drawn? Or should all AI creations be in the public domain? · Would assigning copyright to AI works create an imbalance in the public domain due to the massive scale and velocity at which AI can operate?

I believe that we shouldn't distinguish between autonomous and assisted AI creations because if we look at the original development of LLM's it traces back to a human developing these models. If developers see that models are becoming overly autonomous, then they can limit the models' abilities. I think that AI can't be assigned as an author. If I prompt AI to create an original poem from scratch, I believe that it will search for poems on the internet and call it original even though it generated ideas based on others' work, and it doesn't have to tell the user that it looked up other materials to create its own idea. So, there is a grey area with this question. Just like humans research material and create their own ideas from that material, AI does the same. The line should be drawn where you can see exact resemblance in others' work to the outputs that AIs are giving users. Assigning copyright to AI works would 100% create an imbalance in the public domain because companies with powerful AI systems can generate work and copyright it faster than companies or creators with limited AI systems. Also, new copyrighted works would be coming out daily, and there would be an oversaturation of "original work" drowning out the human aspect of originality.

My question:
Should creators have a right to opt in or out of having their work used for model training? What mechansisms can be implimented to make sure this would be practical? 

I chose this question as the article states the troubles of litigation. It is expensive, time consuming, and complex. There should be a website or app that allows you to upload your work to a safe space where others can view it but there is some sort of firewall or paywall blocking GAI system access to ensure protection of work.

Reflection: 

I really enjoyed reading about copyright access and the troubles that come with copyright, alongside litigation processes. I learned that this process is pretty much out of your control once it hits the public domain. Authors aren't the only ones dealing with this issue, it's everyone who publishes work for the public and it's a coin toss if it's going to be derived or used for model training in GAI systems.


